<!DOCTYPE html>
<html lang="en">
<head>
	<title>Caleb Kelly</title>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
	<link href="https://caleb-m-kelly.github.io/style.css" rel="stylesheet">
</head>
<body class="container-fluid p-0">
<div class="container-fluid rounded">
	<div class="mt-4 p-3 primary text-center">
		<h1 class="topHead">Caleb Kelly</h1>
	</div>
	<nav class="navbar navbar-expand-sm bg-dark navbar-dark justify-content-center">
		<div class="container-fluid justify-content-center">
			<ul class=navbar-nav>
				<li class="nav-item">
					<a class="nav-link active" href="https://Caleb-M-Kelly.github.io/index.html">Home</a>
				</li>
			</ul>
			<ul class=navbar-nav>
				<li class="nav-item">
					<a class="nav-link" href="https://Caleb-M-Kelly.github.io/About.html">About</a>
				</li>
			</ul>
			<ul class=navbar-nav>
				<li class="nav-item">
					<a class="nav-link" href="https://Caleb-M-Kelly.github.io/self-study/Self-Study.html"> Self-Study </a>
				</li>
			</ul>
			<ul class=navbar-nav>
				<li class="nav-item">
					<a class="nav-link" href="https://Caleb-M-Kelly.github.io/projects/Projects.html">Projects</a>
				</li>
			</ul>
		</div>
	</nav>
	<div class="container-fluid">
		<h1 class="primary text-center mt-3 mb-3">Quantum Physics I (MIT 8.04) - MIT OCW</h1>			
		<div class="row">
			<div class="col-2">
			</div>
			<div class="col-8 main">
				&nbsp;&nbsp;This course is Quantum Physics I from MIT. The course information can be found on MIT Opencourseware <a href="https://ocw.mit.edu/courses/8-04-quantum-physics-i-spring-2016/">here</a>. These are my personal notes on each lecture/section.
			</div>
			<div class="col-2">
			</div>
		</div>
		<br>
		<div class="row">
					<div class="col-2">
					</div>
					<div class="col-8 main">
						<b>Section 1: Key Features of Quantum Mechanics</b>

							<p>This lecture introduces the basic concepts of quantum mechanics. Dr. Zwiebach gives a brief history  of quantum physics, then gives a quick preview of the following lecture: first, linearity of the theory will be discussed, then the necessity of complex numbers, then photons and polarization, loss of determinism, and finally superposition.
							</p><p>The first section discusses linearity; in order to do this, basic background on linearity/nonlinearity of theories is needed. Essentially, if we have two solutions to a linear theory, then we can create a third solution by adding them together - such as with Maxwell's electromagnetism. The linearity of electromagnetism can be seen from Maxwell's wave equations, which are linear differential equations. By a comparison, general relativity and classical mechanics are nonlinear theories; conclusions evidenced by the nonlinearity of their corresponding equations. For quantum mechanics, the governing equation (Schrodinger's) is linear, giving rise to an inherently linear theory. Based on the given definition of a linear operator, and the fact that Schrodinger's equation can be put into the form L(psi) = 0, it is shown that the equation is linear.
							</p><p>Dr. Zwiebach claims quantum mechanics is the first theory making meaningful use of complex numbers. Although complex numbers are used in other theories, they are typically "auxiliary" - that is, they may appear during calculations, but only temporarily, never as the final answer. Quantum mechanics, on the other hand, uses complex numbers much more directly. Since the wavefunction itself is complex, we cannot measure it directly because our measurements must be real; therefore, we can only measure the wavefunction indirectly.
							</p><p>Quantum mechanics also comes with a loss of determinism; I did not expect this to be derived from the concepts of photons. As is explained, physicists came to realize, through observing phenomena such as the photelectric effect, that light can act as a wave and as a particle. However, if we pass a beam of light consisting of identical photons (a laser) through a polarizer, some particles are absorbed while others are not; parts of particles are not absorbed because the light exiting the polarizer is of the same frequency. We cannot tell beforehand which photons will be absorbed, meaning we cannot reliably predict the system's behavior with certainty. That is, the present does not necessarily determine the future.
							</p><p>Next, superposition in quantum mechanics was discussed. Since this is a linear theory, adding two possible states together gives another possible reality allowed by the theory. The first example used to demonstrate superposition is the Mach-Zehnder interferometer. With a specific configuration, there is an interference effect at BS2 which leads to a full beam at D0, but no beam at D1. However, since two photons should not interfere to give zero photons (where would the energy go?), this can only be interpreted as a photon interfering with itself; it takes both paths through the interferometer simultaneously. Furthermore, using the state-based description of photon polarization - a|photon; x> + b|photon; y>, a,b complex - it can be shown that this corresponds to two real parameters, the same degrees of freedom as classical mechanics. A similar superposition effect can be seen in electron spin. As electrons can be spin up or spin down in a chosen direction, electrons with unknown spin direction are in a superposition of the two states - they are spinning up and down simultaneously.
							</p><p>Finally, quantum entanglement is introduced. Quantum entanglement can occur when states of two or more particles are considered. When two particles are being considered, we can write a state of two particles as a tensor product of the individual states. The state of the two particle system can be described with superpositions of these products. If we can factor these superpositions such that the first factor is all of one particle, and the other factor is states from only the second particle, then the system can be specified by the states of the individual particles.</p>

						<b>Section 2: Experiments with Photons</b>
							<p>Having acquired a broad overview of quantum physics, the next lecture seeks to dive deeper into the Mach-Zehder Interferometer. By learning more about the interferometer, we can build on what we've learned from the last lecture while also displaying more of the whacky qualities of quantum physics. As before, the diagram shows the configuration for the interferometer, with two beam splitters, two mirrors, and two detectors.
							</p><p>At any x position of the diagram, a photon can either be in the top beam or the bottom beam; this means the state can be written as a vector [a, b] where aa* + bb* = 1; the norms squared correspond to probabilities of being found on the top (a) or bottom (b). When a photon hits a beam splitter, it is transformed according to whether it hit the BS from the top or the bottom; the mathematical effect is multiplying the vector by a matrix [[s, u], [t, v]]. Since we want to keep probabilities normalized, the sum of square norms of entries down each column have to add up to one; this restricts each entry to be +/- 1/sqrt(2). Based on the results the possible matrices give, BS1 and BS2 correspond to matrices where s and v are negative, respectively. Using this matrix representation, we see that blocking the bottom path with an absorbing block will lead to a probability of 1/4 that the photon reaches the lower detector; this is increased from the zero it was.
							</p><p>As an example of an application, Dr. Zwiebach introduces the concept of an Elitzur-Vaidman Bomb, which is a bomb with a photon detector for an activation trigger. If we were to classically test the trigger mechanism for viability, this would involve exploding the bomb; this would undermine our goal. However, if we use the bomb's photon detector in place of the absorbing block in the above setup, there will be 1/4 probability of the photon ending on the bottom detector without exploding the bomb. By contrast, if the photon detector is not working and allows the photon through, the only possibility is for the photon to end on the top detector. Therefore, if we test the detector and a photon ends up on the bottom, then we know the detector is working; otherwise, if the photons end up on the top detector every time, the detector is not working. Theoretically, we could imagine a system in which the probability of the photon ending up on the bottom without a corresponding explosion is much higher than with an explosion, allowing us to detect viable bombs with high efficiency and low risk of loss.
							</p><p>This phenomenon is called an interaction-free measurement, which does not occur in classical systems and is further evidence supporting quantum theory.</p>

						<b>Section 3: Particles and Waves</b>
							<p>This lecture further discusses wave-particle duality, beginning with the photoelectric effect and moving on to discuss Compton scattering and matter waves.
							</p><p>The photoelectric effect is the phenomenon where light causes metal to emit electrons, causing a photoelectric current. There were, however, some observations that puzzled physicists at the time: below a threshold frequency, there is no current, the magnitude of the current is proportional to intensity of the light, and the energy of the electrons is not related to the intensity of the light. Previously, physicists knew how this process works at high wavelengths; these laws broke down for shorter wavelengths because their predictions resulted in the "ultraviolet catastrophe." Fortunately, the concept of photons as discrete particles of light explains the photoelectric effect.
							</p><p>If the work required to eject an electron is W, and the energy of a photon is hv, then the kinetic energy of the electron is the difference between the two: E = hv - W. After a dimensional analysis, we can see that [h] = [E/v] = LML/T, or length times momentum. We can use this to construct a length quantity attributed to a given massive particle by taking the momentum as mc, then dividing h/p to get the Compton wavelength. Since we used v = c, this corresponds to a photon with energy equal to the rest energy of the given particle.
							</p><p>Relativistically speaking, the equation E&sup2; - (pc)&sup2; = (mc&sup2;)&sup2; governs the relationship between energy, momentum, and rest mass. For a photon, we have E = pc; combined with E = hv we get p = h/lambda. Under Thomson (classical) scattering, light rebounding off electrons will result in light of the same frequency; by comparison, experimental results show that the wavelength changes. With the concept of photons, this makes sense: by energy/momentum conservation, entire photons cannot be absorbed, but photons must lose some energy to the electrons (changing the wavelength).
							</p><p>Using Compton's ideas, Louis de Broglie hypothesized that the equation for wavelength, h/p, could be extended to all particles. The idea that particles are also waves hints at interesting effects: waves diffract/interfere. It makes sense that we don't observe many of these effects in our physical world, because our length scales are very large; by comparison, h seems to approach 0, and so does the wavelength. This would imply that quantum effects tend to become negligible at large length scales.</p>

						<b>Section 4: Velocities and Free Particles</b>
							<p>To any free particle we can now associate a matter wave with the de Broglie wavelength. This wave is called the wavefunction of the particle. In classical mechanics, we know our laws should be invariant under a Galilean transformation. However, changing Galilean frames does not preserve quantum wavelength as it would for a normal wave. Therefore, since wavefunctions aren't necessarily frame-invariant, they cannot be measured in different frames with the same result: they are not directly measurable.
							</p><p>If we form a packet of waves, where the function &phi;(k) is multiplying the wavefunctions exp(i(kx - w(k) t)) through an integration over k, we can imagine the function phi as having a peak around k = K0. Then taking &psi;(x,t) and substituting a first order expansion of w(k) about K0 gives us a phase factor multiplied by an integral. This integral can be rewritten as &psi;(x - dw/dk | K0 * t, 0). Taking the absolute value removes the phase factor. Suppose the packet peaks at some point x = X0. Then we can set it equal to the x value passed into &psi; for the previous expression, getting x = x0 + vt, where v is dw/dk evaluated at K0. So, the wave packet can be thought of as moving with this velocity of the peak.
							 </p><p>Then, Dr. Zwiebach moves on to discuss the wavefunction for a free particle. Based on the de Broglie relations, we have a couple options for forming superpositions, those being sine, cosine, and exponentials. Since sine and cosine superpositions will all vanish identically at certain times, exponential superpositions are the only ones that make sense. As a matter of convention, physicists choose a positive time dependence to get &psi;(x, t) = exp(i(k*x - wt)) for the free particle wavefunction. With this wavefunction, p = hk and E = hw.</p>

						<b>Section 5: Wavefunctions</b>
							<p>Excitingly, we discovered the wave function of a free particle! In quantum theory, the wavefunction is meant to be the most complete description of a system available; to get information from the wavefunction, we use operators to act on them. In the case of momentum, we can get the momentum by taking the derivative with respect to x and multiplying by h/i, leaving the wavefunction multiplied by the value of the momentum. The action we've performed is called an operator, and if we analogize the operator to a matrix, then the equivalent of the constant is an eigenvalue. Not all wavefunctions are eigenvalues, because not all states have defined momentum. Therefore, in correlation with an eigenvector, we call our particular &psi; an eigenstate of momentum.
							</p><p>Similarly, we can construct an operator for the energy of a state. The operator ih*d/dt accomplishes this, but so does the operator p&sup2; /2m, which simplifies to E = -hh/2m * d&sup2;/dx&sup2;. Acting these two operators on the wavefunction and setting them equal gives the Schrodinger equation for a free particle wavefunction. Notice that adding two solutions with different k's creates a superposition that is also a solution; yet, acting with the momentum operator does not produce an eigenvalue.
							</p><p>However, if we want to include particles in potentials, we will need to alter the Schrodinger equation to do so. If E = pp/2m + V(x,t), then we simply substitute this in for the energy operator in the Schrodinger equation. The new energy operator, including potential energy, is called the Hamiltonian operator. The full Schrodinger equation can be written as ih d/dt &psi; = H&psi;. Notice that the equation is only first order in time, so the wavefunction at any specific instant in time will also determine it for the future. Additionally, the function is linear, allowing superpositions to work.
							</p><p>We've been introducing a number of different operators. Notice that each of these operators is linear - that is, they are distributive over addition as well as associative. Furthermore, we can construct the commutator of two different operators [A, B] = AB - BA. For example, [p, x] = ih. This builds further on the correspondence between QM concepts and linear systems; interestingly, an entirely different viewpoint of QM, called the Heisenburg picture can be constructed from this correspondence.
							</p><p>The Schrodinger equation can be extended to multiple dimensions by adding corresponding components to the differential operators. If we do this, we can see that coordinate and momentum operators will commute if they act on different position variables.
							</p><p>Ultimately, the wavefunction needs an interpretation; we need to understand the physical meaning of it. The answer is that the wavefunction represents the probability of a particle; integrating the square norm of the wavefunction over a space interval will give the probability of measuring the particle to be in that region.</p>

						<b>Section 6: Probability & Evolution</b>
							<p>Now that we know how to find the wavefunction, the next important step is to interpret it. Our interpretation of the wavefunction is that dP, where P is probability, is equal to the square norm of the wavefunction times dx. Then the integral over all x (-&infin;, &infin;) of the square norm should be equal to 1, corresponding to certainty that we'll find the particle in this range. This would also imply that the wave function must approach 0 at -&infin; and &infin; so this can occur. Finally, d&psi;/dx should be bounded.
							</p><p>Technically, the constant scaling of &psi; doesn't provide any new information, so wavefunctions technically only need to integrate to a constant, N, so we can divide it by the square root of N to <i>normalize</i> it. So, we could say our requirement is for the wavefunction to be <i>normalizable</i> (or square-integrable). Notice that the wavefunctions we derived for free particles are not normalizable, but we can take an infinite sum of them to get normalizable wavefunctions.
							</p><p>If we impose the condition that, given a normalized wavefunction at t=0, the wavefunction will also be normalized for other t. Then dN/dt = 0. Since N is the square integral of the wavefunction over x, the time derivative will commute with the integration; then we can use the product rule to get two terms under the integral sign. Finally, we can substitute results from the schrodinger equation for the time derivatives of &Psi; and its conjugate to get an equation that amounts to needing the hermiticity of H.
							</p><p>Finally, Dr. Zwiebach performs a number of calculations on d&rho;/dt to get the result of the one-dimensional probability current, J, of the wavefunction and shows that the conditions for normalizability imply that dN/dt = 0, using the definition for the probability current to reach this conclusion.
							</p><p>In one dimension, if the probability of a particle being found in an interval changes, it is due to probability current at the boundary of this interval. In three dimensions, this can be seen from Gauss's law where the boundary of a volume is a closed surface.</p>

						<b>Section 7: Wavepackets & Uncertainty</b>
							<p>For the integral form of a symmetric wavepacket at t=0, we can see the packet has a width of about &delta;k. It is shown that &psi;(x,0) is real if and only if &phi;*(-k) = &phi;*(k). Back with the original integral, which is actually a Fourier transform of &phi;, we can offset the integration variable by a constant, representing the location of the peak. Eventually, we use the argument that the phase kx, when large, will "wash out" the integral as it gets larger. So, most of the integral contributions will happen when kx is within a certain range. From this, we get to the uncertainty relation &delta;x&delta;k &thickapprox; 1.
							</p><p>When we look at general features of the wavepacket, we can expand &omega;(k) in terms of k and check to see the magnitude of the second order term. Under a short time evolution, the second order term can be ignored if the magnitude of the resulting phase change is significantly less than 1. Using the uncertainty relations we found in the first part of the lecture, we eventually get &delta;pt/m << &delta;x as the condition for the wavepacket not changing shape.
							</p><p>If we know the wavefunction at a time (say t = 0), then we can find &Psi;(x, t) from it. We can compute &Phi;(k) using a Fourier transform and use it to rewrite &Psi;(x,0) as a superposition of plane waves (the Fourier representation of psi) and multiply the integrand by exp(-i w(k) t). Carrying out this integral (literally or numerically) will provide &Psi;(x,t).</p>

						<b>Section 8: Momentum Space & Expectation</b>
							<p>We already know the momentum space and position space formulations of wavefunctions can be transformed into each other with Fourier transforms. If we chain the transforms together, however, we can find a formula for the delta function; the delta function is a special function for which integration becomes evaluation at a point. Using delta functions, we can find Parseval's theorem that normalization for &Psi; is analogous to normalization for &Phi; and if we write k in terms of p, we can also analogously find the probability density for the particle to be found with a momentum in a range as opposed to a position.
							</p><p>We can use the idea of expectation values to generalize this concept to other observables. To find the expected value of a random variable, we multiply each possible value by its corresponding probability and add up all the contributions. Similarly, since the probability function is |&psi;|^2 and we are 'adding' over an infinite number of infinitely small probabilities, we are really just integrating the quantity we are looking for times the probability density from -&infin; to &infin;. When we do some calculations, we find that the expectation value of an operator is the integral over all possibilities of &psi;* times the operator acting on &psi;.
							</p><p>Now, how do expectation values behave under time evolution? Assuming the definition of the operator itself doesn't depend on time, we can perform calculations involving substituting the Schrodinger equation for d&psi;/dt and the hermiticity of the Hamiltonian to get the following result: i&hbar; &lt;Q&gt; = &lt;[Q, H]&gt; , where [.,.] is the commutator.</p>

						<b>Section 9:</b>
							<p>This lecture starts off with a reminder of Hermiticity and a 'briefer notation': (&psi;&#8321;,&psi;&#8322;) = &#8747;&psi;&#8321;&psi;&#8322; dx . Using this notation, it becomes easier to prove a number of claims, the first of which is that the expectation value of a Hermitian operator is a real quantity. The second is that the eigenvalues of a Hermitian operator are real - If Q&psi; = q&psi;, then &lt;Q&gt; = (&psi; Q&psi;) = (&psi;, q&psi;) = q(&psi;, &psi;) = q . Since the expectation value is real, so is the eigenvalue.
							</p><p>The third claim is that we can show that the eigenfunctions can be re-organized so that they become orthonormal, i.e. that (&psi;<sub>i</sub>,&psi;<sub>j</sub>) = &delta;<sub>ij</sub>. This would mean for i=j, the integral should be normalized to 1. It also means for two different eigenfunctions, there can be no overlap. When we use hermiticity of Q, we get (q<sub>j</sub> - q<sub>i</sub>)(&psi;<sub>i</sub>, &psi;<sub>j</sub>) = 0. Although this would imply there is no overlap as long as the eigenvalues aren't the same, this doesn't cover the degenerate case where the two q's could take the same value. However, what ultimately happens is we can take linear combinations of the degenerate wavefunctions.
							</p><p>The fourth claim is that the eigenfunctions of Q form a "complete set of basis functions." Basically, every possible &Psi; can be written as a linear combination of the eigenfunctions of Q. &Psi; =  &Sigma;a<sub>i</sub>&psi;<sub>i</sub> where we can find the a<sub>i</sub> by taking the inner product (&psi;<sub>i</sub>, &Psi;) .
							</p><p>The "Measurement Postulate" states that if we measure the Hermitian operator Q  in the state &Psi;, all the possible outcomes are among the eigenvalues q<sub>i</sub>. Moreover, the probability to get the result q<sub>i</sub> is |a<sub>i</sub>|<sup>2</sup>. Then the wavefunction 'collapses' to the eigenfunction &psi;<sub>i</sub>. This is because we are now 100% certain the wavefunction is in the state with the value q<sub>i</sub>. If the eigenvalue is degenerate, we are 100% certain it is in one of the degenerate states with this value. Any immediately subsequent measurements will give the same result.
							</p><p>For a normal random variable, (&Delta;Q)<sup>2</sup> = <span class="over">Q<sup>2</sup></span> - (<span class="over">Q</span>)<sup>2</sup>, where the overlines represent the expectation values. This also goes for the quantum mechanical equivalent with the operator and bracket notations. Then we can also show (&Delta;Q)<sup>2</sup> = &lt;(Q - &lt;Q&gt;)<sup>2</sup>&gt; Using the definition of expectation value, it can also be shown that the variance is equal to &int;dx (Q - &lt;Q&gt;)&Psi;(x)|<sup>2</sup> If the variance is zero, then this implies Q&Psi; = &lt;Q&gt;&Psi; which would mean &Psi; is an eigenstate of Q.</p>

						<b>Section 10:</b>
							<p>In the Schrodinger equation, when the potential V is time independent the equation becomes separable. This means the full solution can be factored into time-dependent and coordinate-dependent components. These special solutions are called 'stationary states' because observables that don't explicitly depend on time will be fully time independent on such a state. If we factor &Psi;(x, t) into g(t) and &psi;(x), substituting into the Schrodinger equation gives g(t) = e<sup>-iEt/h</sup> and H&psi;(x) = E&psi;(x) which is known as the time-independent Schrodinger equation: ((-h<sup>2</sup>/2m) d<sup>2</sup>/dx<sup>2</sup> + V(x))&psi;(x) = E&psi;(x). The expectation value of a time-independent operator on a stationary state is also time independent. A linear combination (superposition) of stationary states with different energies is not stationary, since we cannot factorize the full state in a superposition.
							</p><p>Since the Hamiltonian is Hermitian, we can organize the energy eigenstates into the form of a complete set of orthonormal functions. For the time independent Schrodinger equation, the form of &psi; is entirely dependent on the form of the potential V. Dr. Zwiebach makes the reasonable assumption that our potential does not contain derivatives/exponents of delta functions, in which case our wavefunction is required to be continuous. If it wasn't, &psi;' would have delta functions, so &psi;'' would have derivatives of delta functions, so from Schrodinger's equation &psi; would also have to have derivatives of delta functions. If V is continuous then so are &psi; and its derivatives. If V has finite discontinuities then &psi;' is continuous. If V contains delta functions, then &psi;'' does, too but &psi;' has only finite discontinuities. Finally, if V has a hard wall then &psi;' will be discontinuous at the wall.</p>

						<b>Section 11:</b>
							<p>The "infinite square well" is the potential function that is zero for some finite interval, with two hard walls on both ends. Since particles with infinite potential energy can't exist, the probability of finding the particle outside the interval is zero; so, the wavefunction must vanish at the boundaries of the well. Otherwise, the Schrodinger equation resembles that of a free particle within the walls. Defining k<sup>2</sup> := 2mE/h<sup>2</sup>, the eigenvalue equation simplifies to &psi;'' = -k<sup>2</sup>&psi;, giving &psi;(x) = c<sub>1</sub>cos(kx) + c<sub>2</sub>sin(kx). Since the potential has hard walls at x=0 and x=a. Since cosine cannot satisfy this condition, our only contributor is the sine term. Substituting the second boundary condition gives c<sub>2</sub>sin(ka) = 0 implies ka = n&pi; implies k<sub>n</sub> = n&pi;/a so &psi;<sub>n</sub>(x) = sin(n&pi;x/a). To normalize all these wavefunctions we simply multiply them by (2/a)<sup>1/2</sup>, which we get from applying the fact that the integral of the probability amplitude over the interval is 1. Note that the nth state has n-1 nodes, and since the potential is symmetric in x the wavefunctions are either symmetrical or antisymmetrical. Finally, the &psi;<sub>n</sub>(x)  form a complete set. Any possible state of the particle (any wavefunction that vanishes at the end points of the interval) can be represented as an expansion in the &psi;<sub>n</sub>.
							</p><p>By contrast, the finite square well is exactly the same except that the walls are not hard - they represent walls of the same finite energy level. For our case, we will represent the well as a negative offset: V(x) = 0 except for a finite interval between |x| = a, where it is -V<sub>0</sub>. We can now introduce the concept of the <b>bound state</b>. A bound state contrasts the typical free particle state because, unlike the free particle, a bound state wavefunction is normalizable. This occurs when the particle would classically be unable to escape the well. In our case, the particle classically would be unable to escape the well if the energy is below the barrier, or E < 0. On the other hand the minimum bound on the energy is -V<sub>0</sub>, since this is the minimum value of the potential in any region of space.
							</p><p>Based on the form of the equation, observe that in general when the energy is greater than the potential function the wavefunction will curve toward the x-axis, but if the energy is less than the potential function at a point the wavefunction will curve away from the x-axis. We will want to choose exponentials for the outer intervals and a trigonometric function for the inner interval. Since the potential is symmetrical, we know the solutions will be either symmetric or antisymmetric. We define k = 2m(V<sub>0</sub> - |E|)/h<sup>2</sup>. For the even case, the inner interval wavefunction is cos(kx) because cosine is even. For the outer interval, we can define &kappa;<sup>2</sup> = 2m|E|/&hbar;<sup>2</sup> so that the Schrodinger equation becomes &psi;'' = &kappa;<sup>2</sup>&psi;. A physically meaningful general solution is &psi;(x) = ae<sup>-&kappa;x</sup>. We then have to match the points where the intervals meet, such that cos(ka) = Ae<sup>-&kappa;x</sup>, and because &psi;' is continuous we have -k sin(ka) = -&kappa;Ae<sup>-&kappa;x</sup>. Combining these we have ka tan(ka) = &kappa;a . From the definitions of k and &kappa;, k<sup>2</sup>+&kappa;<sup>2</sup>=2mV<sub>0</sub>/&hbar;<sup>2</sup>. So we have the following: k<sup>2</sup>+&kappa;<sup>2</sup>=2mV<sub>0</sub>/&hbar;, &kappa;=k tan(ka) for even solutions.
							</p><p>In the odd case, the only change made is setting &psi;(x) = Ae<sup>-&kappa;|x|</sup> for |x|&gt;a and &psi;(x) = sin(kx) for |x|&lt;a. We still have k<sup>2</sup>+&kappa;<sup>2</sup>=2mV<sub>0</sub>/&hbar; but the second equation becomes &kappa;=-k cot(ka) for odd solutions.
							</p><p>In both cases, the solution set at a given energy level consists of the intersection of a circle and a tangential function. There are a finite number of intersecting points for a given energy level, implying the bound energy states are quantized.</p>

						<b>Section 12:</b>
							<p>The first theorem to be proved is that the energy eigenstates &psi;(x) can be chosen to be real. If we take the complex conjugate of the eigenstate equation we get another solution, &psi;*, with the same energy. Then we can get two real solutions from superpositioning them like so: (&psi;+&psi;*)/2 and -i(&psi;-&psi;*)/2. A corollary of this is that any bound state of a one-dimensional potential would have to be real, since such bound states do not admit degenerate eigenstates so &psi;=&psi;*.
							</p><p>Now we'll prove a result we've already used multiple times: If the potential is even, then the energy eigenstates can be chosen to be even or odd. Starting with the original eigenstate equation and substituting in -x for x, since V(x)=V(-x) we have the following: &psi;''(-x) + &alpha;(E - V(x))&psi;(-x) = 0. This would imply that &psi;(-x) is another solution with the same energy. Then we can form symmetric and antisymmetric solutions from (&psi;(x)+&psi;(-x))/2 and ((&psi;(x)-&psi;(-x))/2. Specifically for one-dimensional bound states, degenerate solutions can't exist so &psi;(x) and &psi;(-x) must represent the same solution, implying &psi;(x) = &psi;(-x).
							</p><p>The semi-classical approximation of eigenvalues is considered next. For a particle in a constant potential, the momentum is (2mK)<sup>1/2</sup>, where K is kinetic energy. Then the de Broglie wavelength is &hbar;/p. By contrast, if V(x) = &alpha;x, then the kinetic energy and momentum will be position dependent. If the potential is slowly varying, then the approximation here is that the de Broglie wavelength is position dependent with &lambda;(x) = h/p(x). Since the wavelength is inversely proportional to the momentum, the wavefunction will have a shorter wavelength for small x and a longer wavelength for increasing x. The actual condition for the semiclassical approximation is &lambda;(x)|dV/dx| &Lt; |V(x)|, where the left side represents the change in V over the distance &lambda;(x).
							</p><p>If we consider a varying potential that would cause a particle to oscillate, this particle would classically spend more time where its momentum and kinetic energy are smaller. If we apply this intuition to set the fraction of time required to cross a dx to be related to the probability amplitude at the dx, we have |&psi;(x)|<sup>2</sup> &sime; dt/T, where T is the half-period of oscillation. Then substituting dt = dx/v(x) gives |&psi;(x)|<sup>2</sup>dx &sime; dx/v(x)T = m dx/Tp(x) implies the probability is proportional to 1/p(x). Yet we must interpret this as being the average probability being inversely proportional to momentum, since if momentum were very high the wavefunction would oscillate rapidly while the momentum would not and the literal interpretation of the equation simply doesn't support this. So we say that the amplitude of &psi; is proportional to 1/(p(x))<sup>1/2</sup> is proportional to (&lambda;(x))<sup>1/2</sup>.
							</p><p>If we think of the infinite square well, a classical particle would oscillate evenly throughout the box, so it would spend an equal amount of time in each part of the box. In the quantum picture, as the momentum increases the number of times the wavefunction oscillates within the box increases, spreading the probability density more and more evenly throughout the box. At very high momentums, we would approach the classical picture. Specifically, the nth energy eigenstate would have probability density of (2/a)sin<sup>2</sup>(n&pi;x/a) so over distances larger than a/n it would essentially look like the classical picture.</p>

						<b>Section 13:</b>
							<p>We next consider the case of the delta potential well, presented as V(x) = -&alpha;&delta;(x), &alpha; &gt;0, where the potential is infinitely negative at x=0. If we examine it by taking the limit as the finite square well potential becomes infinitely thin and deep, we expect the wavefunction's derivative to be discontinuous at x=0. By the eigenvalue equation, we can see that with an inner interval of infinitesimal width we have only exponentials on either side of the origin as options: &psi;(x) = Ae<sup>-&kappa;|x|</sup>. The Schrodinger equation gives a constraint on the discontinuity when it is integrated in an asymptotically small region about the origin: integrating from -&straightepsilon; to &straightepsilon;, we get (-h<sup>2</sup>/2m)(&psi;'(&straightepsilon;) - &psi;'(-&straightepsilon;) - &alpha;&psi;(0)=0. Substituting in our definition for &psi;(x), we have that the first term becomes -&kappa;Ae<sup>-&kappa;&straightepsilon;</sup>-&kappa;Ae<sup>-&kappa;&straightepsilon;</sup>, then as &straightepsilon;&rarr;0 it becomes -2&kappa;A, so the finl equation is -2&kappa;A = -2m&alpha;A/&hbar;<sup>2</sup> so &kappa; = m&alpha;/&hbar;<sup>2</sup>. Then the energy of the bound state, E=-&hbar;<sup2</sup>&kappa;<sup>2</sup>/2m, must be -m&alpha;<sup>2</sup>/2&hbar;<sup>2</sup>
							</p><p>Remember the infinite potential well, where &psi;<sub>n</sub> had n-1 nodes/zeroes (not including endpoints)? This property can be generalized to other potentials such that V&rarr;&infin; as x&rarr;&infin;. Imagine an infinite square well, but instead of having a flat bottom, the well's bottom is V(x). If we pick a minimum and set the width of this well to be infinitely small, the node theorem will hold because minimums are locally flat. Since the walls are hard walls, the wavefunction becomes identically zero at the boundaries. If we increase the width of the well, the only way a node can be introduced is if a wavefunction minimum develops, touches the x-axis, and finally dips below the x-axis to create an additional two nodes. However, since &psi;'(x)=0 at a minimum and &psi;(x)=0 at the x-axis, when the minimum crosses the x-axis there will be a point where both &psi; and &psi;' are 0, which from Schrodinger's equation would imply &psi;(x):=0. So long as the eigenfunctions of the potential are equivalent to the eigenfunctions in the limit as the width of the well approaches infinity, then the number of nodes of the eigenfunctions are the same as the number of nodes as the infinite square well: the node theorem.
							</p><p>Finally, we'll take a look at the simple harmonic oscillator. It's like the classical spring with F=-kx. So E=mv<sup>2</sup>/2+kx<sup>2</sup>/2, with the second term being the potential V(x). Then the angular frequency is &omega;=&radic;(k/m). This is important because a general potential under a Taylor series expansion about a minimum will have this form. Overall, the quantum form of this is presented via H=p<sup>2</sup>/2m + (1/2)m&omega;<sup>2</sup>x<sup>2</sup>.</p>
							
					</div>
					<div class="col-2">
					</div>
				</div>
	</div>
</div>
</body>
</html>
